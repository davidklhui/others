{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWGoC4wvMeFBQ0ulUor+Uk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidklhui/stochastic-modelling/blob/main/Slot_design_using_Markov_Chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "author: David K.L. Hui"
      ],
      "metadata": {
        "id": "n3dNnEtuNJ4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project will discuss different approach to model slot game mathematics using the concept of Markov Chains."
      ],
      "metadata": {
        "id": "fnJTcqVBNN7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Introduction"
      ],
      "metadata": {
        "id": "FNaJ0MjMNhXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1: Background\n",
        "\n",
        "In previous projects, we discussed the mathematics of 3x3 and 5x3 slot game design including simulations; finding feasible solutions using hit frequency and RTP; payout allocations; and probability calculations.\n",
        "\n",
        "In these projects, the main assumption is that, we assume that the outcomes of the reels are completely independent between game. This is useful when designing basic game as there will not have a dependencies between game.\n",
        "\n",
        "However, in many modern casino, the slot machine itself has its own internal mechanism. For example, make consecutive large prize and medium prize be impossible.\n",
        "\n",
        "To control this kind of prize behavior, very basic if-then-else flow control programming is capable of achieve this. Another possible way is to use Markov Chains. Using Markov Chains, we can easily visualize the transition of different states (using state-space diagram, or simply the transition probability matrix), the probability of transitions, as well as the limiting distributions.\n",
        "\n",
        "It is worth to note that, all key concepts we have used like Hit Frequency and RTP are still applicable, although the calculation may be a bit differs."
      ],
      "metadata": {
        "id": "IUfEGPnjQkFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2: Stochastic Processes"
      ],
      "metadata": {
        "id": "hCe57EojUNAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Processes is a sequence of random variables over time. We usually classify a stochasic process using **state** and **stage**.\n",
        "\n",
        "1. State: the states of the process is the possible value of the random variables. e.g.: non-negative integers for a queue; +1 / 0/ -1 to represent win/draw/loss of a game;\n",
        "\n",
        "2. Stage: also the time, which is the time the random variables are collected. e.g: discrete time (n), or continuous time (t)\n",
        "\n",
        "Stochasic Processes is a extremely broad class in probability theory. In our project, we will use a specific type called Markov Chains, a discrete time - discrete states stochasic processes with **Markov property**."
      ],
      "metadata": {
        "id": "IUKktkW9Ux80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3: Markov Chains\n",
        "\n",
        "One important property of a Markov Chains and all kind of Markov processes, are the property called **Markov property**.\n",
        "\n",
        "The Markov Property is a memoryless property of a process, which means that if we know the present state of the process, then the future states are independent of the past history.\n",
        "\n",
        "Mathematically, the Markov property stated that, given the present state $X_n$, the state of the future state $X_{n+1}, X_{n+2}, ...$ is independent of the past $X_{n-1}, X_{n-2}, ...$, i.e.\n",
        "\n",
        "$$\n",
        "P(X_{n+1}=j | X_n = i, X_{n-1} = i_{n-1}, X_{n-2} = i_{n-2}, ....) = P(X_{n+1}=j | X_n = i) \\ \\forall i,j,n\n",
        "$$\n",
        "\n",
        "In general, we needs either the **State-Space Diagram** or the **Transition Probability Matrix** to represents a Markov Chains. In this project, we will simply use the transition probability matrix, **P**, where its rows represent the current state, columns represent the next state, and the element $p_{i,j}$ represents the transition probability moving from state i to state j, i.e.\n",
        "\n",
        "$$\n",
        "p_{i,j} = P(X_{n+1} = j | X_n = i) \\ \\forall i,j\n",
        "$$\n"
      ],
      "metadata": {
        "id": "rnDpk53_ZmAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4: Limiting Distribution\n",
        "\n",
        "One important concept of a stochastic process is the long run behavior. For specific Markov Chains, we can derive its limiting distribution (also known as stationary distribution).\n",
        "\n",
        "For the randomness property of a stochastic process, it is impossible to know the exact state of process (unless for specific class of chains like periodic, or reached the absorption states). However, if the limiting distribution exists, we can know that, the proportion of time the process is in specific state regardless of the initial state.\n",
        "\n",
        "This concept is particular useful for us to define the Hit frequency and RTP because\n",
        "1. we know on average the proportion of time in different states, especially in the state of not winning, so we can calculate the hit frequency\n",
        "2. similar, we know how often it is in different prize state, so we can calculate the RTP as well\n",
        "\n",
        "\n",
        "To calculate the limiting distribution, we can use the famous relationship\n",
        "\n",
        "$$\n",
        "\\pi = \\pi P\n",
        "$$\n",
        "\n",
        "where $\\pi$ is the limiting distribution in row vector, $P$ is the transition probability matrix\n"
      ],
      "metadata": {
        "id": "umoZCiJhzbGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Modeling Examples\n",
        "\n",
        "The above are just a tip of the area of Markov Chains and Stochastic Processes. There are many wonderful application area that may be useful for iGaming industry.\n",
        "\n",
        "In this project, we will consider to model the game with the followings:\n",
        "1. Classify the results into at least 4 states: Not win (0); Small Prize (1); Medium Prize (2); Large Prize (3); where for those who just got medium and large prize cannot get large prize in their immediate next stage\n",
        "2. Homogeneous Markov Chains: the transition probability is time-invariant, i.e. independent of the stage.\n",
        "3. Markov Property holds: given the latest state is enough to tell the transition probability, regardless of the past\n",
        "4. Limiting Distribution exists: as we mentioned, limiting distribution exists only for specific conditions holds. However, it is no harm to assume it exists, if not, try use another transition probability matrix.\n"
      ],
      "metadata": {
        "id": "kJWWhpsD4pyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1: Example\n",
        "\n",
        "Here we provide a very basic setup:\n",
        "\n",
        "Step1: Define a transition probability matrix <br/>\n",
        "Step2: find the limiting distribution through eigen problem (eigenvector with eigenvalue = 1) <br/>\n",
        "Step3: find Prob(win) <br/>\n",
        "Step4: distribute the payout according to the probability, and calculate the RTP"
      ],
      "metadata": {
        "id": "hZqqGkH17KcP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mLAzQc2kTTm"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.array([[0.69, 0.205, 0.1, 0.005], [0.7, 0.2, 0.099, 0.001], [0.9, 0.09, 0.01, 0], [0.99, 0.01, 0, 0]])\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kZ37RSRDxT5",
        "outputId": "e9f9089a-9b40-4db0-cbef-fb0b16d90e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.69 , 0.205, 0.1  , 0.005],\n",
              "       [0.7  , 0.2  , 0.099, 0.001],\n",
              "       [0.9  , 0.09 , 0.01 , 0.   ],\n",
              "       [0.99 , 0.01 , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You may take a look, for a long run, the N-steps transition probability will become this\n",
        "from numpy.linalg import matrix_power\n",
        "\n",
        "p = matrix_power(P, 10000)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ7rLwA_EZcQ",
        "outputId": "0e63406a-3c1c-497b-a207-00a808879184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71221088, 0.19281342, 0.09122183, 0.00375387],\n",
              "       [0.71221088, 0.19281342, 0.09122183, 0.00375387],\n",
              "       [0.71221088, 0.19281342, 0.09122183, 0.00375387],\n",
              "       [0.71221088, 0.19281342, 0.09122183, 0.00375387]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use solve the eigen equation to get the limiting distribution\n",
        "# since it works only for column vector, so first we need to transpose the transition probability matrix\n",
        "# then find the column vector associated with eigenvalue = 1\n",
        "# finally, re-scale the eigenvector to sum = 1 (by default, it is of norm=1)\n",
        "\n",
        "from numpy.linalg import eig\n",
        "\n",
        "eigenvalues, eigenvectors = eig(np.transpose(P))"
      ],
      "metadata": {
        "id": "U6QNBKyH7ppp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ElTkCB8Hmi",
        "outputId": "1b9dfdb2-3cd1-4cdd-bfca-f20c3b28d7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.        , -0.10229626,  0.01652407, -0.01422782])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt2fBYol70Wk",
        "outputId": "f11843ed-d497-44bb-ded4-dcdfa1b7149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.95794711,  0.82418853,  0.68136944, -0.64133836],\n",
              "       [ 0.2593404 , -0.45994563, -0.69796184,  0.70684662],\n",
              "       [ 0.12269637, -0.32845472, -0.14734329, -0.24120953],\n",
              "       [ 0.00504908, -0.03578818,  0.16393569,  0.17570126]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.transpose(eigenvectors)[0]\n",
        "p = p/sum(p)\n",
        "\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqh781ZvTXfe",
        "outputId": "654e04ab-33fc-46c7-8a2e-cc3d2f53cd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.71221088, 0.19281342, 0.09122183, 0.00375387])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform further analysis\n",
        "p0, p1, p2, p3 = p"
      ],
      "metadata": {
        "id": "GotKRsc8VdJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYtRk2gNZLTW",
        "outputId": "94adb2f9-032c-4d74-c278-097d50d56887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7122108798046978"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1, p2, p3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By0llCghZL-S",
        "outputId": "a330a1b4-2a4b-44f7-c0b2-6630e478741f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.19281341769910385, 0.09122183467947585, 0.0037538678167225933)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P(Win) = Hit frequency in the long run\n",
        "1 - p0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4qe1pmqZMm8",
        "outputId": "58f1bdcf-f068-48b0-f26e-3746493e22b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28778912019530223"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suggested Payout\n",
        "c = 10\n",
        "\n",
        "r1 = c / 3 / p1\n",
        "r2 = c / 3 / p2\n",
        "r3 = c / 3 / p3\n",
        "\n",
        "\n",
        "r1, r2, r3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-6ONWgkZVmP",
        "outputId": "610b7963-c473-4e42-f135-18d2af459eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17.287870175794442, 36.54095913599626, 887.9730177189836)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the payout for each prize in sensible values\n",
        "r = [0, 15, 35, 1000]"
      ],
      "metadata": {
        "id": "_jE2VPw3ZjwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# expected payout\n",
        "np.dot(r, p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMnuVgVgZkvE",
        "outputId": "8d51738b-9207-445f-d961-94a9ac505360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.838833295990806"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sim(N):\n",
        "  traces = []\n",
        "\n",
        "  latest_state = 0\n",
        "\n",
        "  for i in range(N):\n",
        "    x = np.random.choice(a=range(4), size=1, p=P[latest_state])[0]\n",
        "    traces.append(x)\n",
        "    latest_state = x\n",
        "\n",
        "  return traces\n",
        "\n",
        "\n",
        "N = 1000000\n",
        "traces = sim(N)"
      ],
      "metadata": {
        "id": "itY6Y_vvgWG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(traces)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0kjg2NphHVI",
        "outputId": "58bcaeaa-f24e-4909-eb5d-f18bef045323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 711722, 2: 91130, 1: 193338, 3: 3810})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verify the proportion of states\n",
        "[xx * N for xx in p]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k_lzg2uhnNM",
        "outputId": "e781b96c-7c5c-409d-e57b-4d8d3383fc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[712210.8798046978, 192813.41769910385, 91221.83467947585, 3753.8678167225935]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSBy7icxkzfa",
        "outputId": "43d6ba92-f354-4c2c-feaa-9eb2c7278276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 15, 35, 1000]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RTP\n",
        "sum(list(map(lambda x: r[x], traces))) / (N*c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzPgYYbEkzww",
        "outputId": "7545ef57-afcf-4c8f-d700-da8aeef3749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.989962"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check longest 0:\n",
        "longest = 0\n",
        "run = 0\n",
        "for i in traces:\n",
        "#  print(f\"{i}, {r[i+2]}\")\n",
        "\n",
        "  if r[i]==0:\n",
        "    run += 1\n",
        "  else:\n",
        "    longest = max(longest, run)\n",
        "    run = 0\n",
        "\n",
        "\n",
        "# longest loss = 24\n",
        "longest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DqXHVdJ8bUK",
        "outputId": "f1425688-31b2-427f-ad8d-7cdcc118aa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2: Example 2\n",
        "\n",
        "Suppose this time, we wish to add two more states to represent loss: -1, and -2. So, states {0, -1, -2} are the states representing a loss, but their transition to win is differernt, the more they loss, the transition probability to 1 (small prize), 2 (medium prize), 3 (large prize), will be larger slighly. What ever a win to loss will back to state 0 first."
      ],
      "metadata": {
        "id": "W3uSA8qSlEki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.array([[0.6, 0, 0, 0.26, 0.135, 0.005],\n",
        "              [0.65, 0, 0, 0.22, 0.125, 0.005],\n",
        "              [0, 0.69, 0, 0.205, 0.1, 0.005],\n",
        "              [0, 0, 0.7, 0.2, 0.099, 0.001],\n",
        "              [0, 0, 0.9, 0.09, 0.01, 0],\n",
        "              [0, 0, 0.99, 0.01, 0, 0]])\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oUShnIHWV16",
        "outputId": "bfee767f-43cb-4919-f06b-3856089005f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6  , 0.   , 0.   , 0.26 , 0.135, 0.005],\n",
              "       [0.65 , 0.   , 0.   , 0.22 , 0.125, 0.005],\n",
              "       [0.   , 0.69 , 0.   , 0.205, 0.1  , 0.005],\n",
              "       [0.   , 0.   , 0.7  , 0.2  , 0.099, 0.001],\n",
              "       [0.   , 0.   , 0.9  , 0.09 , 0.01 , 0.   ],\n",
              "       [0.   , 0.   , 0.99 , 0.01 , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[sum(x) for x in P]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D6aEpBYiUyz",
        "outputId": "318e80ab-499e-4fca-9e28-0ad465d92ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 1.0, 0.9999999999999999, 0.9999999999999999, 1.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You may take a look, for a long run, the N-steps transition probability will become this\n",
        "from numpy.linalg import matrix_power\n",
        "\n",
        "p = matrix_power(P, 10000)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip4jvAyMekRP",
        "outputId": "1ce126aa-73fa-4b8e-db66-6b8cce5b01df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744],\n",
              "       [0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744],\n",
              "       [0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744],\n",
              "       [0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744],\n",
              "       [0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744],\n",
              "       [0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "        0.00362744]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use solve the eigen equation to get the limiting distribution\n",
        "# since it works only for column vector, so first we need to transpose the transition probability matrix\n",
        "# then find the column vector associated with eigenvalue = 1\n",
        "# finally, re-scale the eigenvector to sum = 1 (by default, it is of norm=1)\n",
        "\n",
        "from numpy.linalg import eig\n",
        "\n",
        "eigenvalues, eigenvectors = eig(np.transpose(P))"
      ],
      "metadata": {
        "id": "WFjzfKM5eo4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isZx_888etsm",
        "outputId": "bd1185a8-1707-4703-9e65-36c22118324a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.00000000e+00+0.j        ,  5.46320879e-02+0.29808585j,\n",
              "        5.46320879e-02-0.29808585j, -2.53918219e-01+0.j        ,\n",
              "       -4.58939655e-02+0.j        ,  5.48008700e-04+0.j        ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHPGDrF0euRm",
        "outputId": "982ea05a-1ba7-4ee8-ad0c-017ce2e4c776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.86649279e-01+0.j        , -6.88614914e-01+0.j        ,\n",
              "        -6.88614914e-01-0.j        ,  5.79021741e-01+0.j        ,\n",
              "         6.82606339e-01+0.j        ,  6.86162374e-01+0.j        ],\n",
              "       [-3.61014941e-01+0.j        ,  5.77766889e-01-0.3157944j ,\n",
              "         5.77766889e-01+0.3157944j , -7.60672637e-01+0.j        ,\n",
              "        -6.78294331e-01+0.j        , -6.32802156e-01+0.j        ],\n",
              "       [-5.23210059e-01+0.j        ,  1.82171674e-01+0.22459656j,\n",
              "         1.82171674e-01-0.22459656j,  2.79925567e-01+0.j        ,\n",
              "         4.51153864e-02+0.j        , -5.02581285e-04+0.j        ],\n",
              "       [-4.49237525e-01+0.j        , -3.64411264e-02+0.0769563j ,\n",
              "        -3.64411264e-02-0.0769563j , -8.75606601e-02+0.j        ,\n",
              "        -2.12411149e-01+0.j        , -1.16505619e-01+0.j        ],\n",
              "       [-2.23353577e-01+0.j        , -3.38427512e-02+0.01550622j,\n",
              "        -3.38427512e-02-0.01550622j, -9.12368538e-03+0.j        ,\n",
              "         1.63740408e-01+0.j        , -2.06023948e-01+0.j        ],\n",
              "       [-7.80360892e-03+0.j        , -1.03977102e-03-0.00126468j,\n",
              "        -1.03977102e-03+0.00126468j, -1.59032581e-03+0.j        ,\n",
              "        -7.56653358e-04+0.j        ,  2.69671930e-01+0.j        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.transpose(eigenvectors)[0].real\n",
        "p = p/sum(p)\n",
        "\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXz7YST1eu3a",
        "outputId": "58e99180-3112-4c26-ad1a-e4d185b51fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241 ,\n",
              "       0.00362744])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform further analysis\n",
        "pm2, pm1, p0, p1, p2, p3 = p"
      ],
      "metadata": {
        "id": "8aoVPtAhex6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P(Win) = Hit frequency in the long run\n",
        "p1+p2+p3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvGxBdxee7aL",
        "outputId": "e2335890-5af2-446a-acad-6683263d5a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31627598117000605"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suggested Payout\n",
        "c = 10\n",
        "\n",
        "r1 = c / 3 / p1\n",
        "r2 = c / 3 / p2\n",
        "r3 = c / 3 / p3\n",
        "\n",
        "\n",
        "r1, r2, r3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTP_lZidfArq",
        "outputId": "f521cfae-69df-400b-d186-2d9f75d37132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15.962372328758876, 32.10558223990266, 918.9205539589251)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the payout for each prize in sensible values\n",
        "r = [0, 0, 0, 15, 30, 1000]"
      ],
      "metadata": {
        "id": "Mn8xrHZwfTes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# expected payout\n",
        "np.dot(r, p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iOKWBVQfZHm",
        "outputId": "8001c31b-6a22-4680-c863-a539533be0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.874534146865146"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sim(N):\n",
        "  traces = []\n",
        "\n",
        "  latest_state = 0\n",
        "\n",
        "  for i in range(N):\n",
        "    x = np.random.choice(a=[-2,-1,0,1,2,3], size=1, p=P[latest_state+2])[0]\n",
        "    traces.append(x)\n",
        "    latest_state = x\n",
        "\n",
        "  return traces\n",
        "\n",
        "\n",
        "N = 1000000\n",
        "traces = sim(N)"
      ],
      "metadata": {
        "id": "HxN7yPZCfcsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(traces)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOL1sKibfyZV",
        "outputId": "64d9e4d2-0080-4652-e5d0-0364ee5c8f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 208498, 0: 242872, 2: 103920, -1: 167645, -2: 273453, 3: 3612})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verify the proportion of states\n",
        "[xx * N for xx in p]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7-KP822f1kT",
        "outputId": "3d19f168-cbcf-4f7e-b097-243652a310ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[272699.1751402867,\n",
              " 167814.87700940706,\n",
              " 243209.9666803001,\n",
              " 208824.43190024942,\n",
              " 103824.10474370638,\n",
              " 3627.4445260502143]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-pDFcDDf4r4",
        "outputId": "1714ba24-0fc1-4225-bf01-71cb9aeecc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 15, 30, 1000]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RTP\n",
        "sum(list(map(lambda x: r[x+2], traces))) / (N*c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvufd9sNf46g",
        "outputId": "1f1258e0-facf-4c06-c5a0-7b45154d1a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.985707"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check longest 0:\n",
        "longest = 0\n",
        "run = 0\n",
        "for i in traces:\n",
        "#  print(f\"{i}, {r[i+2]}\")\n",
        "\n",
        "  if r[i+2]==0:\n",
        "    run += 1\n",
        "  else:\n",
        "    longest = max(longest, run)\n",
        "    run = 0\n",
        "\n",
        "\n",
        "# longest straight losses\n",
        "longest\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K3WzNQe5WBH",
        "outputId": "bd592b69-7a3f-4f2c-c6f8-62134fba16d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3: Discussion\n",
        "\n",
        "From these 2 examples, we can see that we can define different states of win and loss (including consecutive losses like in subsection 2.2). In general, we can define as many states as we wish. The major challenges of this method are:\n",
        "\n",
        "1. How to determine the transition probability between states\n",
        "2. How to achieve the desire limiting distribution\n",
        "\n",
        "Because in this Markov Chains construction, unlike the previous projects we can apply Dirichlet Distribution to simulate the probability of occurrence of different symbols, there are far more restrictions to apply Dirichlet Distribution than before:\n",
        "1. some state is inaccessible from specific state (like state 3 cannot reach states {-1,-2} directly)\n",
        "2. probability to reach state 3 must be the lowest, then 2 and 1\n",
        "3. for states {-2,-1} have a slighly larger probability to reach states {1,2,3}\n",
        "\n",
        "Hence, we need to develop another method to reconstruct the transition probability matrix given the desired limiting distribution"
      ],
      "metadata": {
        "id": "DcGXCAnzhN0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Reconstruction of transition probability matrix\n",
        "\n",
        "In this section, we will introduce a method to reconstruct a transition probability matrix $P$ given a desired limiting distribution $\\pi$ of any finite states"
      ],
      "metadata": {
        "id": "dTFrVZqxk85i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1: Mathematics Background\n",
        "\n",
        "Recall from Section 1.4, if the limiting distribution $\\pi$ of a Markov Chain exists, then it must satisfy\n",
        "\n",
        "$$\n",
        "\\pi = \\pi P\n",
        "$$\n",
        "\n",
        "Where $K$ be the number of states, with\n",
        "\\begin{align}\n",
        "\\displaystyle\\sum_{i=1}^K \\pi_i &= 1 \\\\\n",
        "\\displaystyle\\sum_{j=1}^K P_{i,j} &= 1 \\ \\forall i\n",
        "\\end{align}\n",
        "\n",
        "Here we assume $\\pi$ is known, while $P$ is an unknown square matrix.\n",
        "\n",
        "To find a sensible $P$, we can convert this problem into a optimization problem, and try to find a \"good\" solution of $P$ satisfying all relationships\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "15CcIGuIBuYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1: Optimization Problem\n",
        "\n",
        "Because the equations $\\pi = \\pi P$ must be satisfied, we can define the following objective function, using similar concept like the sum of square deviation between $\\pi$ and $\\pi P$:\n",
        "\n",
        "$$\n",
        "f(p) = \\displaystyle\\sum_{j=1}^K (\\pi_j - \\sum_{i=1}^K \\pi_i P_{i,j})^2\n",
        "$$\n",
        "\n",
        "where $p$ is vector of all $i,j$ entries of $P$.\n",
        "\n",
        "\n",
        "\n",
        "We wish to find a $p$ minimize $f(p)$\n",
        "\n",
        "$$\n",
        "p^* = \\underset{p}{\\mathrm{argmin}} f(p)\n",
        "$$\n",
        "\n",
        "The rationale of this method is because:\n",
        "1. $f(p) \\ge 0$\n",
        "2. We wish to solve $f(p) = 0$\n",
        "\n",
        "What we can do is either solve the equations by hand (treat it is system of linear equations, see Appendix A), or by optimization problem using computer.\n",
        "\n",
        "However, solving the system of equations may be tedious, we can see this results in Appendix A, the only simple calculation is 2-states. For 3 / 4-states systems (or even more), the derivation is tedious, and potential issues may occur (not just typo or human errors, see **A.3: Four-states solutions** for more details).\n",
        "\n",
        "\n",
        "Also, if we need to put somewhat more constraints (e.g. some entries must be greater than the others), stating all equations one by one may be time consuming.\n",
        "So, converting the question into a optimization problem help easing many steps.\n",
        "\n",
        "\n",
        "p.s.: We should note that, there is a obvious solution of $P$, which is an identity matrix. However, if we have slightly more constraints (like we know some entries, or specific relationship orders say, some probability must be greater than another), then the the solution of identity matrix will not be obtained\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZNIUTg_7B5fM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2: Scipy for optimization problem example"
      ],
      "metadata": {
        "id": "f3UdjZT-AQw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1: Example 1 revisit"
      ],
      "metadata": {
        "id": "KVn-_Z4K3AJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Given the limiting distribution from Example 2.1\n",
        "pi = np.array([0.71221088, 0.19281342, 0.09122183, 0.00375387])\n",
        "n = len(pi)\n",
        "\n",
        "# small tolerance\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Objective function\n",
        "def objective(P):\n",
        "    P = P.reshape((n, n))\n",
        "    deviation = 0\n",
        "    for j in range(n):\n",
        "        deviation += (pi[j] - np.dot(pi, P[:, j]))**2\n",
        "    return deviation\n",
        "\n",
        "# Constraints: each row sums to 1\n",
        "def row_sum_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    return np.sum(P, axis=1) - 1\n",
        "\n",
        "\n",
        "\n",
        "# Known value entries constraints\n",
        "def known_value_entries_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    constraints = [\n",
        "        P[2, 3],\n",
        "        P[3, 2],\n",
        "        P[3, 3],\n",
        "        P[3, 1] - 0.01\n",
        "    ]\n",
        "    return constraints\n",
        "\n",
        "\n",
        "\n",
        "# Known zero entries constraints\n",
        "def inequality_entries_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    constraints = [\n",
        "        P[0, 0] - P[0, 1] - epsilon,\n",
        "        P[0, 1] - P[0, 2] - epsilon,\n",
        "        P[0, 2] - P[0, 3] - epsilon,\n",
        "        P[1, 0] - P[1, 1] - epsilon,\n",
        "        P[1, 1] - P[1, 2] - epsilon,\n",
        "        P[1, 2] - P[1, 3] - epsilon,\n",
        "        P[3, 0] - P[3, 1] - epsilon,\n",
        "        P[3, 1] - P[3, 2] - epsilon,\n",
        "\n",
        "        P[3, 0] - P[2, 0] - epsilon,\n",
        "        P[2, 0] - P[1, 0] - epsilon,\n",
        "        P[1, 0] - P[0, 0] - epsilon,\n",
        "        P[0, 1] - P[1, 1] - epsilon,\n",
        "        P[1, 1] - 2*P[2, 1] - epsilon,\n",
        "        P[2, 1] - P[3, 1] - epsilon,\n",
        "        P[0, 2] - P[1, 2] - epsilon,\n",
        "        P[1, 2] - 10*P[2, 2] - epsilon,\n",
        "        P[0, 3] - 5* P[1, 3] - epsilon\n",
        "    ]\n",
        "    return constraints\n",
        "\n",
        "\n",
        "# Non-negativity constraint\n",
        "bounds = [(0, 1) for _ in range(n*n)]\n",
        "\n",
        "# Initial guess for P\n",
        "P0 = np.ones((n, n)) / n\n",
        "\n",
        "# Formulate and solve the optimization problem\n",
        "# the constraints with making zero entries must be the first constraint\n",
        "constraints = [\n",
        "    {'type': 'eq', 'fun': known_value_entries_constraint},\n",
        "    {'type': 'ineq', 'fun': inequality_entries_constraint},\n",
        "    {'type': 'eq', 'fun': row_sum_constraint},\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "result = minimize(objective, P0.flatten(), bounds=bounds, constraints=constraints)\n",
        "\n",
        "# Reshape the solution back to matrix form\n",
        "P_optimal = result.x.reshape((n, n))\n",
        "\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "print(\"Optimized Transition Matrix P:\")\n",
        "print(P_optimal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFy01lnb3ywA",
        "outputId": "308f4948-b91a-4685-f711-580cbb157bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Transition Matrix P:\n",
            "[[0.69197604 0.20294852 0.10001034 0.0050651 ]\n",
            " [0.69629861 0.20278411 0.09994214 0.00097514]\n",
            " [0.8923363  0.09981673 0.00784697 0.        ]\n",
            " [0.99       0.01       0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above, we have put 4 equality constraints, with some inequality constraints (to confirm the strict ordering of the probabilities, with 3 have explicitly stated the multiple). Then, we obtained a optimal solution which is highly close to the real matrix $P$:\n",
        "\n"
      ],
      "metadata": {
        "id": "L3yCwcJJ7aHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.array([[0.69, 0.205, 0.1, 0.005], [0.7, 0.2, 0.099, 0.001], [0.9, 0.09, 0.01, 0], [0.99, 0.01, 0, 0]])\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6-WI7hr-Rdi",
        "outputId": "bc856e41-c6b2-4042-e894-362dcdd597e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.69 , 0.205, 0.1  , 0.005],\n",
              "       [0.7  , 0.2  , 0.099, 0.001],\n",
              "       [0.9  , 0.09 , 0.01 , 0.   ],\n",
              "       [0.99 , 0.01 , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify their closeness, and the validity of the optimal solution:"
      ],
      "metadata": {
        "id": "1UEXS3mv-R8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import matrix_power\n",
        "\n",
        "# for lazyiness, just use power instead of finding the exact limiting distribution\n",
        "pp = matrix_power(P_optimal, 10000000)[0]\n",
        "print(f\"found solution: {pp}\")\n",
        "print(f\"required solution: {pi}\")\n",
        "\n",
        "\n",
        "print(f\"diff in norm: {np.linalg.norm(pp-pi)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXjPBj0y-ac5",
        "outputId": "73e51406-c647-4f5b-b561-c7ea527a0aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found solution: [0.71221558 0.19277772 0.09121127 0.00379543]\n",
            "required solution: [0.71221088 0.19281342 0.09122183 0.00375387]\n",
            "diff in norm: 5.599075522185434e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, we can reconstruct the transition probability matrix, under the desired limiting distribution, and some requied constraints (including exact value, or simply the ordering)"
      ],
      "metadata": {
        "id": "9lj8Jz4c-g8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2: Example 2 revisit"
      ],
      "metadata": {
        "id": "YeVFXz3e-5Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Given stationary distribution\n",
        "pi2 = np.array([0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241, 0.00362744])\n",
        "n = len(pi2)\n",
        "\n",
        "# small tolerance\n",
        "epsilon = 1e-6\n",
        "\n",
        "# Objective function\n",
        "def objective(P):\n",
        "    P = P.reshape((n, n))\n",
        "    deviation = 0\n",
        "    for j in range(n):\n",
        "        deviation += (pi2[j] - np.dot(pi2, P[:, j]))**2\n",
        "    return deviation\n",
        "\n",
        "# Constraints: each row sums to 1\n",
        "def row_sum_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    return np.sum(P, axis=1) - 1\n",
        "\n",
        "\n",
        "\n",
        "# Known value entries constraints\n",
        "def known_value_entries_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    constraints = [\n",
        "        P[0, 1],  # P_12 = 0\n",
        "        P[0, 2],  # P_13 = 0\n",
        "        P[1, 1],  # P_22 = 0\n",
        "        P[1, 2],  # P_23 = 0\n",
        "        P[2, 0],  # P_31 = 0\n",
        "        P[2, 2],  # P_33 = 0\n",
        "        P[3, 0],  # P_41 = 0\n",
        "        P[3, 1],  # P_42 = 0\n",
        "        P[4, 0],  # P_51 = 0\n",
        "        P[4, 1],  # P_52 = 0\n",
        "        P[4, 5],  # P_56 = 0\n",
        "        P[5, 0],  # P_61 = 0\n",
        "        P[5, 1],  # P_62 = 0\n",
        "        P[5, 4],  # P_65 = 0\n",
        "        P[5, 5],  # P_66 = 0\n",
        "        P[0, 5] - 0.005,  # P_16 = 0.005\n",
        "        P[1, 5] - 0.005,  # P_26 = 0.005\n",
        "        P[2, 5] - 0.005,  # P_36 = 0.005\n",
        "        P[3, 5] - 0.001,  # P_46 = 0.001\n",
        "        P[5, 2] - 0.99,  # P_63 = 0.99\n",
        "    ]\n",
        "    return constraints\n",
        "\n",
        "\n",
        "\n",
        "# Known zero entries constraints\n",
        "def inequality_entries_constraint(P):\n",
        "    P = P.reshape((n, n))\n",
        "    constraints = [\n",
        "      P[1, 0] - P[0, 0] - epsilon, # P_21 > P_11\n",
        "      P[0, 3] - P[1, 3] - epsilon, # P_14 > P_24\n",
        "      P[0, 4] - P[1, 4] - epsilon, # P_15 > P_25\n",
        "      P[1, 3] - P[2, 3] - epsilon, # P_24 > P_34\n",
        "      P[1, 4] - P[2, 4] - epsilon, # P_25 > P_35\n",
        "      P[4, 2] - P[3, 2] - epsilon, # P_53 > P_43\n",
        "      P[3, 3] - 2*P[4, 3] - epsilon, # P_44 > 2*P_54\n",
        "      P[3, 4] - 1.1*P[4, 4] - epsilon # P_45 > 2*P_55\n",
        "    ]\n",
        "    return constraints\n",
        "\n",
        "\n",
        "# Non-negativity constraint\n",
        "bounds = [(0, 1) for _ in range(n*n)]\n",
        "\n",
        "# Initial guess for P\n",
        "P0 = np.ones((n, n)) / n\n",
        "\n",
        "# Formulate and solve the optimization problem\n",
        "# the constraints with making zero entries must be the first constraint\n",
        "constraints = [\n",
        "    {'type': 'eq', 'fun': known_value_entries_constraint},\n",
        "    {'type': 'ineq', 'fun': inequality_entries_constraint},\n",
        "    {'type': 'eq', 'fun': row_sum_constraint},\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "result = minimize(objective, P0.flatten(), bounds=bounds, constraints=constraints)\n",
        "\n",
        "# Reshape the solution back to matrix form\n",
        "P_optimal = result.x.reshape((n, n))\n",
        "\n",
        "print(\"Optimized Transition Matrix P:\")\n",
        "print(P_optimal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-APG1lR3_bsG",
        "outputId": "43821cb8-12f1-4f0e-a1b4-562327f5142e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Transition Matrix P:\n",
            "[[0.60116626 0.         0.         0.26769527 0.12613847 0.005     ]\n",
            " [0.6485291  0.         0.         0.24542286 0.10104804 0.005     ]\n",
            " [0.         0.68960292 0.         0.22096668 0.08443039 0.005     ]\n",
            " [0.         0.         0.73668965 0.15727119 0.10503916 0.001     ]\n",
            " [0.         0.         0.82587567 0.0786351  0.09548923 0.        ]\n",
            " [0.         0.         0.99       0.01       0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# true P\n",
        "P = np.array([[0.6, 0, 0, 0.26, 0.135, 0.005],\n",
        "              [0.65, 0, 0, 0.22, 0.125, 0.005],\n",
        "              [0, 0.69, 0, 0.205, 0.1, 0.005],\n",
        "              [0, 0, 0.7, 0.2, 0.099, 0.001],\n",
        "              [0, 0, 0.9, 0.09, 0.01, 0],\n",
        "              [0, 0, 0.99, 0.01, 0, 0]])\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YezkuoGj_1ry",
        "outputId": "62eb5c5e-055f-4ea1-9025-f03621ae3743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6  , 0.   , 0.   , 0.26 , 0.135, 0.005],\n",
              "       [0.65 , 0.   , 0.   , 0.22 , 0.125, 0.005],\n",
              "       [0.   , 0.69 , 0.   , 0.205, 0.1  , 0.005],\n",
              "       [0.   , 0.   , 0.7  , 0.2  , 0.099, 0.001],\n",
              "       [0.   , 0.   , 0.9  , 0.09 , 0.01 , 0.   ],\n",
              "       [0.   , 0.   , 0.99 , 0.01 , 0.   , 0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for lazyiness, just use power instead of finding the exact limiting distribution\n",
        "pp = matrix_power(P_optimal, 10000000)[0]\n",
        "print(f\"found solution: {pp}\")\n",
        "print(f\"required solution: {pi2}\")\n",
        "\n",
        "\n",
        "print(f\"diff in norm: {np.linalg.norm(pp-pi2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5X5hsHP_tIl",
        "outputId": "b05c0751-ebf2-4171-fb3d-274fec6ff9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found solution: [0.27272562 0.16772135 0.24321439 0.20897134 0.10374002 0.00362728]\n",
            "required solution: [0.27269918 0.16781488 0.24320997 0.20882443 0.1038241  0.00362744]\n",
            "diff in norm: 0.00019523774579662263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3: Formalize the programming code"
      ],
      "metadata": {
        "id": "Da5ywVLI_wGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import final\n",
        "from numpy.linalg import eig\n",
        "\n",
        "\n",
        "class Reconstruct_MC():\n",
        "  def __init__(self, pi):\n",
        "    self.pi = pi\n",
        "\n",
        "    self.n = len(pi)\n",
        "\n",
        "\n",
        "  def known_value_entries_constraint_definition(self, P):\n",
        "    return []\n",
        "\n",
        "  def inequality_entries_constraint_definition(self, P):\n",
        "    return []\n",
        "\n",
        "  @final\n",
        "  def known_value_entries_constraint(self, P):\n",
        "    P = P.reshape((self.n, self.n))\n",
        "    constraints = self.known_value_entries_constraint_definition(P)\n",
        "    return constraints\n",
        "\n",
        "  @final\n",
        "  def inequality_entries_constraint(self, P):\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    P = P.reshape((self.n, self.n))\n",
        "\n",
        "    constraints = self.inequality_entries_constraint_definition(P)\n",
        "\n",
        "    constraints = [x - epsilon for x in constraints] # subtract epsilon to confirm strict inequality\n",
        "    return constraints\n",
        "\n",
        "  # Objective function\n",
        "  @final\n",
        "  def objective(self, P):\n",
        "    P = P.reshape((self.n, self.n))\n",
        "    deviation = 0\n",
        "    for j in range(self.n):\n",
        "        deviation += (self.pi[j] - np.dot(self.pi, P[:, j]))**2\n",
        "\n",
        "    self.deviation = deviation\n",
        "    return deviation\n",
        "\n",
        "  # Constraints: each row sums to 1\n",
        "  @final\n",
        "  def row_sum_constraint(self, P):\n",
        "      P = P.reshape((self.n, self.n))\n",
        "      return np.sum(P, axis=1) - 1\n",
        "\n",
        "  @final\n",
        "  def solve(self):\n",
        "    # Non-negativity constraint\n",
        "    bounds = [(0, 1) for _ in range(self.n * self.n)]\n",
        "\n",
        "    # Initial guess for P\n",
        "    P0 = np.ones((self.n, self.n)) / self.n\n",
        "\n",
        "    # Formulate and solve the optimization problem\n",
        "    # the constraints with making zero entries must be the first constraint\n",
        "    constraints = [\n",
        "        {'type': 'eq', 'fun': self.known_value_entries_constraint},\n",
        "        {'type': 'eq', 'fun': self.row_sum_constraint},\n",
        "        {'type': 'ineq', 'fun': self.inequality_entries_constraint},\n",
        "\n",
        "    ]\n",
        "\n",
        "    result = minimize(self.objective, P0.flatten(), bounds=bounds, constraints=constraints)\n",
        "\n",
        "    # Reshape the solution back to matrix form\n",
        "    self.P_optimal = result.x.reshape((self.n, self.n))\n",
        "    self.eigen()\n",
        "    self.print_result()\n",
        "\n",
        "  @final\n",
        "  def eigen(self):\n",
        "    eigenvalues, eigenvectors = eig(np.transpose(self.P_optimal))\n",
        "\n",
        "    ind = np.where((eigenvalues - 1)**2 < 1e-6)[0][0]\n",
        "\n",
        "    p = np.transpose(eigenvectors)[ind].real\n",
        "    p = p/sum(p)\n",
        "\n",
        "    self.pi_optimal = p\n",
        "\n",
        "  @final\n",
        "  def print_result(self):\n",
        "\n",
        "    print(f\"***************************\")\n",
        "    print(f\"optimal solution: \")\n",
        "    print(self.P_optimal)\n",
        "    print(f\"***************************\")\n",
        "\n",
        "    print(f\"objective function value: {self.deviation}\")\n",
        "\n",
        "    print(f\"given limiting distribution: {self.pi}\")\n",
        "    print(f\"found limiting distribution under optimization: {self.pi_optimal}\")\n",
        "\n",
        "    print(f\"norm of diff: {np.linalg.norm(self.pi_optimal - self.pi)}\")"
      ],
      "metadata": {
        "id": "4aWOPCYnBLHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1: Example 3"
      ],
      "metadata": {
        "id": "p5QzZOKHK4Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# another example apart from the above\n",
        "# here we define 8 states, suppose the first 4 states are no-payouts;\n",
        "# the rest 4 are small prize, small prize2, medium prize, and large prize\n",
        "pi3 = np.array([0.25, 0.10, 0.15, 0.2, 0.13, 0.11, 0.05, 0.01])\n",
        "\n",
        "sum(pi3), sum(pi3[:4]), sum(pi3[4:])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6WBoDkKMoy",
        "outputId": "03f2a299-71a6-4c65-f160-1566b79852f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.7, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# without adding any constraints\n",
        "Reconstruct_MC(pi3).solve()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_VXs9svEAP0",
        "outputId": "da95c96a-9fbf-4f52-afa4-13c94fc5260c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************\n",
            "optimal solution: \n",
            "[[0.30547727 0.08080473 0.15569557 0.23058642 0.12573923 0.0957829  0.00591388 0.        ]\n",
            " [0.20377723 0.11390821 0.14386455 0.17382089 0.13188202 0.11989948 0.08395187 0.02889575]\n",
            " [0.24042922 0.10562569 0.1505602  0.19549471 0.1325864  0.11461259 0.06069118 0.        ]\n",
            " [0.27295325 0.09321521 0.15312789 0.21304057 0.12916282 0.10519774 0.03330253 0.        ]\n",
            " [0.2274104  0.11058068 0.14952392 0.18846716 0.13394662 0.11836932 0.07163743 0.00006447]\n",
            " [0.21165495 0.11279903 0.14575101 0.17870298 0.13257022 0.11938943 0.07984706 0.01928532]\n",
            " [0.16438862 0.11945411 0.13443228 0.14941045 0.12844101 0.12244974 0.10447594 0.07694787]\n",
            " [0.13287772 0.12389082 0.12688646 0.12988209 0.1256882  0.12448995 0.12089519 0.11538957]]\n",
            "***************************\n",
            "objective function value: 9.160190241897695e-08\n",
            "given limiting distribution: [0.25 0.1  0.15 0.2  0.13 0.11 0.05 0.01]\n",
            "found limiting distribution under optimization: [0.24974968 0.10008666 0.14997433 0.199862   0.13001927 0.1100642  0.05019899 0.01004486]\n",
            "norm of diff: 0.0003687523395222328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Reconstruct_MC_eg3(Reconstruct_MC):\n",
        "  def __init__(self, pi):\n",
        "    super().__init__(pi)\n",
        "\n",
        "  def known_value_entries_constraint_definition(self, P):\n",
        "    return [\n",
        "      P[0,1],P[0,2],P[0,3],\n",
        "      P[1,1],P[1,2],P[1,3],\n",
        "      P[2,0],P[2,2],P[2,3],\n",
        "      P[3,0],P[3,1],P[3,3],\n",
        "      P[4,0],P[4,1],P[4,2],\n",
        "      P[5,0],P[5,1],P[5,2],\n",
        "      P[6,0],P[6,1],P[6,2],P[6,6],P[6,7],\n",
        "      P[7,0],P[7,1],P[7,2],P[7,6],P[7,7],\n",
        "\n",
        "\n",
        "#      P[4,3] - 0.70,\n",
        "#      P[5,3] - 0.75,\n",
        "      P[6,3] - 0.85,\n",
        "      P[7,3] - 0.95,\n",
        "\n",
        "    ]\n",
        "\n",
        "  def inequality_entries_constraint_definition(self, P):\n",
        "    c = 0.8 # allow small available buffer\n",
        "    return [\n",
        "\n",
        "      # Row-wise inequalities\n",
        "      P[0,4] - c*P[0,5], P[0,5] - c*P[0,6], P[0,6] - c*P[0,7],\n",
        "      P[1,4] - c*P[1,5], P[1,5] - c*P[1,6], P[1,6] - c*P[1,7],\n",
        "      P[2,4] - c*P[2,5], P[2,5] - c*P[2,6], P[2,6] - c*P[2,7],\n",
        "      P[3,4] - c*P[3,5], P[3,5] - c*P[3,6], P[3,6] - c*P[3,7],\n",
        "\n",
        "      P[4,3] - c*P[4,4], P[4,4] - c*P[4,5], P[4,5] - c*P[4,6], P[4,6] - c*P[4,7],\n",
        "      P[5,3] - c*P[5,4], P[5,4] - c*P[5,5], P[5,5] - c*P[5,6], P[5,6] - c*P[5,7],\n",
        "      P[6,3] - c*P[6,4], P[6,4] - c*P[6,5], P[6,5] - c*P[6,6],\n",
        "\n",
        "\n",
        "      # Column-wise inequalities\n",
        "      P[0,4] - c*P[1,4], P[1,4] - c*P[2,4], P[2,4] - c*P[3,4], P[3,4] - c*P[4,4], P[4,4] - c*P[5,4], P[5,4] - c*P[6,4], P[6,4] - c*P[7,4],\n",
        "      P[0,5] - c*P[1,5], P[1,5] - c*P[2,5], P[2,5] - c*P[3,5], P[3,5] - c*P[4,5], P[4,5] - c*P[5,5], P[5,5] - c*P[6,5], P[6,5] - c*P[7,5],\n",
        "      ## medium and large prize do not offer small available buffer\n",
        "      P[0,6] - P[1,6], P[1,6] - P[2,6], P[2,6] - P[3,6], P[3,6] - P[4,6], P[4,6] - P[5,6], P[5,6] - P[6,6],\n",
        "      P[0,7] - P[1,7], P[1,7] - P[2,7], P[2,7] - P[3,7], P[3,7] - P[4,7], P[4,7] - P[5,7],\n",
        "\n",
        "      # inequalities for specific entries\n",
        "      # P[1,0] - c*P[0,0],\n",
        "      # P[2,1] - c*P[1,0],\n",
        "      # P[3,2] - c*P[2,1],\n",
        "      # P[4,3] - c*P[3,2],\n",
        "      P[5,3] - P[4,3],\n",
        "      P[6,3] - P[5,3],\n",
        "      P[7,3] - P[6,3],\n",
        "\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "-I5qABSVLMXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reconstruct_MC_eg3(pi3).solve()"
      ],
      "metadata": {
        "id": "B8Y9K_kaBDjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1817ecc2-459c-40b1-f335-9b96bad28b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************************\n",
            "optimal solution: \n",
            "[[0.71858343 0.         0.         0.         0.10481349 0.0875649  0.06998807 0.01905011]\n",
            " [0.70543698 0.         0.         0.         0.12037716 0.09901104 0.05877924 0.01639559]\n",
            " [0.         0.67281018 0.         0.         0.14530192 0.11762873 0.05405153 0.01020765]\n",
            " [0.         0.         0.70626808 0.         0.1321022  0.11186017 0.04535551 0.00441404]\n",
            " [0.         0.         0.         0.64528199 0.1651265  0.13982397 0.04535451 0.00441304]\n",
            " [0.         0.         0.         0.64528299 0.16750921 0.15176929 0.03102648 0.00441204]\n",
            " [0.         0.         0.         0.85       0.07857725 0.07142275 0.         0.        ]\n",
            " [0.         0.         0.         0.95       0.02571545 0.02428455 0.         0.        ]]\n",
            "***************************\n",
            "objective function value: 0.00012511627567792869\n",
            "given limiting distribution: [0.25 0.1  0.15 0.2  0.13 0.11 0.05 0.01]\n",
            "found limiting distribution under optimization: [0.24693015 0.09850665 0.14641076 0.20730197 0.13066945 0.11064002 0.04974754 0.00979347]\n",
            "norm of diff: 0.008878041767380501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4: Remark\n",
        "\n",
        "To use this method to reconstruct the tranition probability matrix, there are a few things need to be aware of:\n",
        "1. There may have infinitely many solution that satisfied the given relationship. To avoid (or reduce the number of possible solutions), you need to put more constraints (and it is always preferable)\n",
        "2. Need to review the found solution. The more states will are considering, the higher chance to occur large deviations.\n",
        "3. The given limiting distribution may not achievable. For instance, if you make the limiting distibution is unrealistic for specific states (like if you put a high value for states {-2, -1}), it may end up with a large norm in difference.\n"
      ],
      "metadata": {
        "id": "lc8xJeArb2xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see an unachievable example\n",
        "pi = np.array([0.3, 0.20, 0.10, 0.1, 0.12, 0.12, 0.05, 0.01])\n",
        "print(f\"{sum(pi)}, {sum(pi[:4])}, {sum(pi[4:])}\")\n",
        "\n",
        "Reconstruct_MC_eg3(pi).solve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QjDizUXp3p3",
        "outputId": "c3c52766-f2de-4d85-9f65-151ec121e21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0, 0.7, 0.3\n",
            "***************************\n",
            "optimal solution: \n",
            "[[0.63409672 0.         0.         0.         0.08763374 0.09809622 0.12261902 0.0575543 ]\n",
            " [0.62358379 0.         0.         0.         0.10954093 0.10775526 0.12261802 0.036502  ]\n",
            " [0.         0.72837526 0.         0.         0.13692491 0.13469283 0.000004   0.000003  ]\n",
            " [0.         0.         0.66047533 0.         0.17115489 0.16836478 0.000003   0.000002  ]\n",
            " [0.         0.         0.         0.57559991 0.21394236 0.21045473 0.000002   0.000001  ]\n",
            " [0.         0.         0.         0.46950514 0.2674267  0.26306716 0.000001   0.        ]\n",
            " [0.         0.         0.         0.85       0.07632855 0.07367145 0.         0.        ]\n",
            " [0.         0.         0.         0.95       0.02526571 0.02473429 0.         0.        ]]\n",
            "***************************\n",
            "objective function value: 0.02479930213446342\n",
            "given limiting distribution: [0.3  0.2  0.1  0.1  0.12 0.12 0.05 0.01]\n",
            "found limiting distribution under optimization: [0.17363116 0.10188239 0.13987624 0.21178118 0.16298639 0.16234472 0.03378478 0.01371314]\n",
            "norm of diff: 0.20880354692128722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Conclusion\n",
        "\n",
        "In this project, we discussed the general methodlogy to construct a transition probability matrix of a Markov Chain by desirable limiting distribution (stationary distribution), where some states means for zero payout, and some representing prize level (small / medium / large).\n",
        "\n",
        "Also, we discussed the strength and potential problem when using this approach."
      ],
      "metadata": {
        "id": "xSB1RI4Y74xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "0KcgPFZ8qcH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A: Solutions of linear systems"
      ],
      "metadata": {
        "id": "e1PTAsxh-m_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1: Two-states"
      ],
      "metadata": {
        "id": "xFmINvJ_Tc14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section show that given a 2 states limiting distribution, there are infinitely many solutions"
      ],
      "metadata": {
        "id": "LFXeQFB8TsIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that $\\pi = (\\pi_1, \\pi_2)$ is the given limiting distbribution, where $\\pi_1 + \\pi_2 = 1$.\n",
        "\n",
        "Let the transition probability matrix $P = [p]_{i,j}$, where\n",
        "\\begin{align}\n",
        "p_{1,1} + p_{1,2} &= 1 \\tag{1} \\\\\n",
        "p_{2,1} + p_{2,2} &= 1 \\tag{2}\n",
        "\\end{align}\n",
        "\n",
        "Also, to satisfy the equation $\\pi = \\pi P$, we have the followings:\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 p_{1,1} + \\pi_2 p_{2,1} \\tag{3} \\\\\n",
        "\\pi_2 &= \\pi_1 p_{1,2} + \\pi_2 p_{2,2} \\tag{4}\n",
        "\\end{align}\n",
        "\n",
        "Note that, although there are 4 linear equations, one of them can be generated using the rest 3 (i.e. the matrix of coefficients is not full rank).\n",
        "\n",
        "\n",
        "From $(1)$, let\n",
        "$$p_{1,1} = s \\in (0,1) \\tag{5}$$ then\n",
        "$$p_{1,2} = 1 - s \\tag{6}$$\n",
        "\n",
        "Substitute $(5)$ into $(3)$:\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 s + \\pi_2 p_{2,1} \\\\\n",
        "p_{2,1} &= \\frac{(1-s)\\pi_1}{\\pi_2} \\tag{7}\n",
        "\\end{align}\n",
        "\n",
        "Substitute $(7)$ into $(2)$:\n",
        "\\begin{align}\n",
        "\\frac{(1-s)\\pi_1}{\\pi_2} + p_{2,2} &= 1 \\\\\n",
        "p_{2,2} &= \\frac{\\pi_2 - (1-s)\\pi_1}{\\pi_2}\n",
        "\\end{align}\n",
        "\n",
        "Hence, the transition probability matrix $P$ given the limiting distribution is:\n",
        "\n",
        "\\begin{equation}\n",
        "P =\n",
        "\\begin{bmatrix}\n",
        "s & 1-s \\\\\n",
        "\\frac{(1-s)\\pi_1}{\\pi_2} & \\frac{\\pi_2 - (1-s)\\pi_1}{\\pi_2}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ult9y9oqT6si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where all entries should satisfy $\\in (0,1)$ and row sum up to 1"
      ],
      "metadata": {
        "id": "jr7uFz5kBoxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "\n",
        "import numpy.linalg as LA\n",
        "\n",
        "pi1 = 123/456\n",
        "pi2 = 1 - pi1\n",
        "pi = [pi1, pi2]\n",
        "\n",
        "\n",
        "trials = 0\n",
        "while trials < 100000:\n",
        "  s = np.random.uniform()\n",
        "  # print(f\"s={s}\")\n",
        "\n",
        "  p11 = s\n",
        "  p12 = 1-s\n",
        "  p21 = (1-s)*pi1/pi2\n",
        "  p22 = (pi2 - (1-s)*pi1)/pi2\n",
        "\n",
        "\n",
        "  if p21 > 0 and p22 > 0 and p21 < 1 and p22 < 1:\n",
        "    print(f\"trials={trials}\")\n",
        "    break;\n",
        "\n",
        "  trials += 1\n",
        "\n",
        "P = [[p11, p12], [p21, p22]]\n",
        "\n",
        "print(P)\n",
        "\n",
        "p = LA.matrix_power(P, 10000)[0]\n",
        "p\n",
        "\n",
        "# run for different s, the solution will almost the same\n",
        "print(f\"pi={pi}, found P's limiting distribution={p} \\n, norm of diff = {LA.norm(pi-p)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWnWJ9D6Y4lY",
        "outputId": "4189c54a-cd28-4e42-98e6-3f481e2ce91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trials=0\n",
            "[[0.15222969252722796, 0.847770307472772], [0.3131403838412942, 0.6868596161587058]]\n",
            "pi=[0.26973684210526316, 0.7302631578947368], found P's limiting distribution=[0.26973684 0.73026316] \n",
            ", norm of diff = 5.963287869088852e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, if any one of the entry is determined, then the values of the whole matrix are determined."
      ],
      "metadata": {
        "id": "DMs704piZAUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.2: Three-states"
      ],
      "metadata": {
        "id": "lELQvKa4epjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section show that given a 3 states limiting distribution, there are infinitely many solutions"
      ],
      "metadata": {
        "id": "ri9bqRyDe23P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that $\\pi = (\\pi_1, \\pi_2, \\pi_3)$ is the given limiting distbribution, where $\\pi_1 + \\pi_2 + \\pi_3 = 1$.\n",
        "\n",
        "Let the transition probability matrix $P = [p]_{i,j}$, where\n",
        "\\begin{align}\n",
        "p_{1,1} + p_{1,2} + p_{1,3} &= 1 \\tag{1} \\\\\n",
        "p_{2,1} + p_{2,2} + p_{2,3} &= 1 \\tag{2} \\\\\n",
        "p_{3,1} + p_{3,2} + p_{3,3} &= 1 \\tag{3}\n",
        "\\end{align}\n",
        "\n",
        "Also, to satisfy the equation $\\pi = \\pi P$, we have the followings:\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 p_{1,1} + \\pi_2 p_{2,1} + \\pi_3 p_{3,1} \\tag{4} \\\\\n",
        "\\pi_2 &= \\pi_1 p_{1,2} + \\pi_2 p_{2,2} + \\pi_3 p_{3,2} \\tag{5} \\\\\n",
        "\\pi_3 &= \\pi_1 p_{1,3} + \\pi_2 p_{2,3} + \\pi_3 p_{3,3} \\tag{6}\n",
        "\\end{align}\n",
        "\n",
        "There are 9 variables, but there are 6 equations on hand (and among these 6 equations, some may be derived from the row operations of the others)\n",
        "\n",
        "From $(1)$, let\n",
        "\\begin{align}\n",
        "p_{1,1} &= s \\in (0,1) \\tag{7} \\\\\n",
        "p_{1,2} &= t \\in (0,1) \\ and \\ s+t \\lt 1 \\tag{8}\n",
        "\\end{align}\n",
        "then\n",
        "$$p_{1,3} = 1 - s - t \\tag{9}$$\n",
        "\n",
        "From $(2)$, let\n",
        "\\begin{align}\n",
        "p_{2,1} &= u \\in (0,1) \\tag{10} \\\\\n",
        "p_{2,2} &= v \\in (0,1) \\ and \\ u+v \\lt 1 \\tag{11}\n",
        "\\end{align}\n",
        "then\n",
        "$$p_{2,3} = 1 - u - v \\tag{12}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Substitute $(7)$ and $(10)$ into $(4)$:\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 s + \\pi_2 u + \\pi_3 p_{3,1} \\\\\n",
        "p_{3,1} &= \\frac{(1-s)\\pi_1 - u \\pi_2 }{\\pi_3} \\tag{13}\n",
        "\\end{align}\n",
        "\n",
        "Substitute $(8)$ and $(11)$ into $(5)$:\n",
        "\\begin{align}\n",
        "\\pi_2 &= \\pi_1 t + \\pi_2 v + \\pi_3 p_{3,2} \\\\\n",
        "p_{3,2} &= \\frac{(1-v)\\pi_2 - t \\pi_1 }{\\pi_3} \\tag{14}\n",
        "\\end{align}\n",
        "\n",
        "Substitute $(9)$ and $(12)$ into $(6)$:\n",
        "\\begin{align}\n",
        "\\pi_3 &= \\pi_1 (1-s-t) + \\pi_2 (1-u-v) + \\pi_3 p_{3,3} \\\\\n",
        "p_{3,3} &= \\frac{\\pi_3 - (1-s-t)\\pi_1 - (1-u-v) \\pi_2}{\\pi_3} \\tag{15}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "Hence, the transition probability matrix $P$ given the limiting distribution is:\n",
        "\n",
        "\\begin{equation}\n",
        "P =\n",
        "\\begin{bmatrix}\n",
        "s & t & 1-s-t \\\\\n",
        "u & v & 1-u-v \\\\\n",
        "\\frac{(1-s)\\pi_1 - u \\pi_2 }{\\pi_3} & \\frac{(1-v)\\pi_2 - t \\pi_1 }{\\pi_3} & \\frac{\\pi_3 - (1-s-t)\\pi_1 - (1-u-v) \\pi_2}{\\pi_3}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "p.s.: We also need to check $p_{3,1}$ through $p_{3,3}$ are valid before using them (i.e. $p_{3,j} \\in (0,1)$, and $\\sum_j p_{3,j} = 1$)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8ajOWK22ezao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "\n",
        "import numpy.linalg as LA\n",
        "\n",
        "\n",
        "pi = np.array([123, 456, 80])\n",
        "pi = pi / sum(pi)\n",
        "pi1, pi2, pi3 = pi\n",
        "\n",
        "print(f\"pi={pi}, sum={sum(pi)}\")\n",
        "trials = 0\n",
        "while trials < 100000:\n",
        "  s,t,a = np.random.dirichlet(np.ones(3))\n",
        "  # print(f\"s={s}, t={t}, 1-s-t={a}, sum={s+t+a}\")\n",
        "\n",
        "  u,v,b = np.random.dirichlet(np.ones(3))\n",
        "  # print(f\"u={u}, v={v}, 1-u-v={b}, sum={u+v+b}\")\n",
        "\n",
        "  p11 = s\n",
        "  p12 = t\n",
        "  p13 = a\n",
        "\n",
        "  p21 = u\n",
        "  p22 = v\n",
        "  p23 = b\n",
        "\n",
        "  p31 = ((1-s)*pi1 - u*pi2) / pi3\n",
        "  p32 = ((1-v)*pi2 - t*pi1) / pi3\n",
        "  p33 = (pi3 - (1-s-t)*pi1 - (1-u-v)*pi2) / pi3\n",
        "\n",
        "  if p31 > 0 and p32 > 0 and p33 > 0:\n",
        "    print(f\"trials={trials}\")\n",
        "    break;\n",
        "\n",
        "  trials += 1\n",
        "\n",
        "P = [[p11, p12, p13], [p21, p22, p23], [p31, p32, p33]]\n",
        "print(\"\")\n",
        "print(P[0])\n",
        "print(P[1])\n",
        "print(P[2])\n",
        "\n",
        "p = LA.matrix_power(P, 10000)[0]\n",
        "p\n",
        "\n",
        "# run for different s, the solution will almost the same\n",
        "print(\"\")\n",
        "print(f\"pi={pi}, found P's limiting distribution={p} \\n, norm of diff = {LA.norm(pi-p)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX1iOQHQio2p",
        "outputId": "2ecaf40f-35b9-4ead-b43f-9c1bf81f5eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi=[0.18664643 0.69195751 0.12139605], sum=1.0\n",
            "trials=57\n",
            "\n",
            "[0.7168140634145976, 0.22307968468114034, 0.06010625190426205]\n",
            "[0.052226565165198024, 0.9256589219313663, 0.022114512903435836]\n",
            "[0.13770695605842737, 0.0807591297939586, 0.7815339141476144]\n",
            "\n",
            "pi=[0.18664643 0.69195751 0.12139605], found P's limiting distribution=[0.18664643 0.69195751 0.12139605] \n",
            ", norm of diff = 1.5216008516972997e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are 4 free variables $(s,t,u,v)$, to confirm the transition probability matrix be completely deterministic, we need to ensure at least 4 entries, with not just all from the same row"
      ],
      "metadata": {
        "id": "QxFCkl5Vi1sI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.3: Four-states"
      ],
      "metadata": {
        "id": "E11Pj-SZnehh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section show that given a 4 states limiting distribution, there are infinitely many solutions"
      ],
      "metadata": {
        "id": "Jk45zzKXnkDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$ is the given limiting distbribution, where $\\displaystyle\\sum_{i=1}^4 \\pi_i = 1$.\n",
        "\n",
        "Let the transition probability matrix $P = [p]_{i,j}$, where $\\forall i = 1,2,3,4$\n",
        "\\begin{align}\n",
        "\\displaystyle\\sum_{j=1}^4 p_{i,j} = 1 \\tag{1}\n",
        "\\end{align}\n",
        "\n",
        "Also, to satisfy the equation $\\pi = \\pi P$, we have the followings:\n",
        "\\begin{align}\n",
        "\\pi_j &= \\displaystyle \\sum_{i=1}^4 \\pi_i p_{i,j}  \\tag{2}\n",
        "\\end{align}\n",
        "\n",
        "Using the similar approach:\n",
        "\n",
        "From $(1)$, let\n",
        "\\begin{align}\n",
        "p_{1,1} &= s_1 \\in (0,1) \\tag{3.1} \\\\\n",
        "p_{1,2} &= s_2 \\in (0,1) \\tag{3.2} \\\\\n",
        "p_{1,3} &= s_3 \\in (0,1) \\ and \\ s_1 + s_2 + s_3 \\lt 1 \\tag{3.3}\n",
        "\\end{align}\n",
        "then\n",
        "$$p_{1,4} = 1 - s_1 - s_2 - s_3 \\tag{3.4}$$\n",
        "\n",
        "Similarly,\n",
        "\\begin{align}\n",
        "p_{2,1} &= t_1 \\in (0,1) \\tag{4.1} \\\\\n",
        "p_{2,2} &= t_2 \\in (0,1) \\tag{4.2} \\\\\n",
        "p_{2,3} &= t_3 \\in (0,1) \\ and \\ t_1 + t_2 + t_3 \\lt 1 \\tag{4.3}\n",
        "\\end{align}\n",
        "then\n",
        "$$p_{2,4} = 1 - t_1 - t_2 - t_3 \\tag{4.4}$$\n",
        "\n",
        "\\begin{align}\n",
        "p_{3,1} &= u_1 \\in (0,1) \\tag{5.1} \\\\\n",
        "p_{3,2} &= u_2 \\in (0,1) \\tag{5.2} \\\\\n",
        "p_{3,3} &= u_3 \\in (0,1) \\ and \\ u_1 + u_2 + u_3 \\lt 1 \\tag{5.3}\n",
        "\\end{align}\n",
        "then\n",
        "$$p_{3,4} = 1 - u_1 - u_2 - u_3 \\tag{5.4}$$\n",
        "\n",
        "\n",
        "Sub into $(2)$ with $j=1$\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 p_{1,1} + \\pi_2 p_{2,1} + \\pi_3 p_{3,1} + \\pi_4 p_{4,1} \\\\\n",
        "\\pi_1 &= \\pi_1 s_1 + \\pi_2 t_1 + \\pi_3 u_1 + \\pi_4 p_{4,1} \\\\\n",
        "p_{4,1} &= \\frac{(1-s_1)\\pi_1 - t_1 \\pi_2 - u_1 \\pi_3}{\\pi_4} \\tag{6.1}\n",
        "\\end{align}\n",
        "\n",
        "Sub into $(2)$ with $j=2$\n",
        "\\begin{align}\n",
        "\\pi_2 &= \\pi_1 s_2 + \\pi_2 t_2 + \\pi_3 u_2 + \\pi_4 p_{4,2} \\\\\n",
        "p_{4,2} &= \\frac{(1-t_2)\\pi_2 - s_2 \\pi_1 - u_2 \\pi_3}{\\pi_4} \\tag{6.2}\n",
        "\\end{align}\n",
        "\n",
        "Sub into $(2)$ with $j=3$\n",
        "\\begin{align}\n",
        "\\pi_3 &= \\pi_1 s_3 + \\pi_2 t_3 + \\pi_3 u_3 + \\pi_4 p_{4,3} \\\\\n",
        "p_{4,3} &= \\frac{(1-u_3)\\pi_3 - s_3 \\pi_1 - t_3 \\pi_2}{\\pi_4} \\tag{6.3}\n",
        "\\end{align}\n",
        "\n",
        "And finally,\n",
        "\\begin{align}\n",
        "p_{4,4} = 1 - p_{4,1} - p_{4,2} - p_{4,3} \\tag{6.4}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "Hence, the transition probability matrix $P$ given the limiting distribution is:\n",
        "\n",
        "\\begin{equation}\n",
        "P =\n",
        "\\begin{bmatrix}\n",
        "s_1 & s_2 & s_3 & 1 - s_1 - s_2 - s_3 \\\\\n",
        "t_1 & t_2 & t_3 & 1 - t_1 - t_2 - t_3 \\\\\n",
        "u_1 & u_2 & u_3 & 1 - u_1 - u_2 - u_3 \\\\\n",
        "\\frac{(1-s_1)\\pi_1 - t_1 \\pi_2 - u_1 \\pi_3}{\\pi_4} & \\frac{(1-t_2)\\pi_2 - s_2 \\pi_1 - u_2 \\pi_3}{\\pi_4} & \\frac{(1-u_3)\\pi_3 - s_3 \\pi_1 - t_3 \\pi_2}{\\pi_4} & 1 - (\\text{remaining})\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uzvp7id7noHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although things are derived, the compexity of the relationship tremendously increased. As we need to check all probabilities between (0,1), the last row is highly probably wouldn't get valid results (especially when $\\pi_4$ is extremely small). Even though we can rearrange columns (or reparameterization) and make largest $\\pi_i$ to the right-most, it still be a tedious approach"
      ],
      "metadata": {
        "id": "7slOGDRG5e6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: when pi4 is small -> required a larger number to get valid result\n",
        "\n",
        "import numpy.linalg as LA\n",
        "\n",
        "\n",
        "pi = np.array([456, 789, 1011, 150])\n",
        "pi = pi / sum(pi)\n",
        "pi1, pi2, pi3, pi4 = pi\n",
        "\n",
        "print(f\"pi={pi}, sum={sum(pi)}\")\n",
        "\n",
        "trials = 0\n",
        "while trials < 100000:\n",
        "\n",
        "  s1,s2,s3,s4 = np.random.dirichlet(np.ones(4))\n",
        "  # print(f\"s=({[s1,s2,s3,s4]})\")\n",
        "\n",
        "  t1,t2,t3,t4 = np.random.dirichlet(np.ones(4))\n",
        "  # print(f\"t=({[t1,t2,t3,t4]})\")\n",
        "\n",
        "  u1,u2,u3,u4 = np.random.dirichlet(np.ones(4))\n",
        "  # print(f\"u=({[u1,u2,u3,u4]})\")\n",
        "\n",
        "  p41 = ((1-s1)*pi1 - t1 * pi2 - u1 * pi3) / pi4\n",
        "  p42 = ((1-t2)*pi2 - s2 * pi1 - u2 * pi3) / pi4\n",
        "  p43 = ((1-u3)*pi3 - s3 * pi1 - t3 * pi2) / pi4\n",
        "  p44 = 1 - p41 - p42 - p43\n",
        "\n",
        "  if p41 > 0 and p42 > 0 and p43 > 0 and p44 > 0:\n",
        "    print(f\"trials={trials}\")\n",
        "    break;\n",
        "\n",
        "  trials += 1\n",
        "\n",
        "\n",
        "P = [[s1,s2,s3,s4], [t1,t2,t3,t4], [u1,u2,u3,u4], [p41,p42,p43,p44]]\n",
        "\n",
        "p = LA.matrix_power(P, 10000)[0]\n",
        "p\n",
        "\n",
        "# run for different s, the solution will almost the same\n",
        "print(\"\")\n",
        "print(P[0])\n",
        "print(P[1])\n",
        "print(P[2])\n",
        "print(P[3])\n",
        "\n",
        "print(\"\")\n",
        "print(f\"pi={pi}, found P's limiting distribution={p} \\n, norm of diff = {LA.norm(pi-p)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxYSGuoRrRPQ",
        "outputId": "4bb95e46-038b-43cb-fba9-e8d8b65674e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi=[0.18952618 0.32793017 0.4201995  0.06234414], sum=1.0\n",
            "trials=6697\n",
            "\n",
            "[0.44938198856946354, 0.32964665049746733, 0.11036346479595224, 0.11060789613711668]\n",
            "[0.16499691195866467, 0.5670948437299019, 0.23173585486755163, 0.03617238944388167]\n",
            "[0.10369255130706735, 0.1390361080368806, 0.7267427337992386, 0.03052860685681345]\n",
            "[0.1071072020366206, 0.33785193629984006, 0.28731844461011535, 0.26772241705342403]\n",
            "\n",
            "pi=[0.18952618 0.32793017 0.4201995  0.06234414], found P's limiting distribution=[0.18952618 0.32793017 0.4201995  0.06234414] \n",
            ", norm of diff = 2.822430619597993e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above example we know that if $\\pi_4$ is (extremely) small, then the number of trials will become very large.\n",
        "\n",
        "If we know which $\\pi_i$ is the largest, we can reparameterize the whole set of solutions. For instance, if $\\pi_3$ is the largest, make the $3^{rd}$ one row depends on the rest:\n",
        "\n",
        "\\begin{align}\n",
        "\\pi_1 &= \\pi_1 p_{1,1} + \\pi_2 p_{2,1} + \\pi_3 p_{3,1} + \\pi_4 p_{4,1} \\\\\n",
        "p_{3,1} &= \\frac{(1-s_1)\\pi_1 - t_1 \\pi_2 - v_1 \\pi_4}{\\pi_3} \\tag{1}\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\\pi_2 &= \\pi_1 p_{1,2} + \\pi_2 p_{2,2} + \\pi_3 p_{3,2} + \\pi_4 p_{4,2} \\\\\n",
        "p_{3,2} &= \\frac{(1-t_2)\\pi_2 - s_2 \\pi_1 - v_2 \\pi_4}{\\pi_3} \\tag{2}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\pi_3 &= \\pi_1 p_{1,3} + \\pi_2 p_{2,3} + \\pi_3 p_{3,3} + \\pi_4 p_{4,3} \\\\\n",
        "p_{3,3} &= \\frac{\\pi_3 - v_3 \\pi_4 - s_3 \\pi_1 - t_3 \\pi_2}{\\pi_3} \\tag{3}\n",
        "\\end{align}\n",
        "\n",
        "So, the matrix after reparameterization:\n",
        "\n",
        "\\begin{equation}\n",
        "P =\n",
        "\\begin{bmatrix}\n",
        "s_1 & s_2 & s_3 & 1 - s_1 - s_2 - s_3 \\\\\n",
        "t_1 & t_2 & t_3 & 1 - t_1 - t_2 - t_3 \\\\\n",
        "\\frac{(1-s_1)\\pi_1 - t_1 \\pi_2 - v_1 \\pi_4}{\\pi_3} & \\frac{(1-t_2)\\pi_2 - s_2 \\pi_1 - v_2 \\pi_4}{\\pi_3} & \\frac{\\pi_3 - v_3\\pi_4 - s_3 \\pi_1 - t_3 \\pi_2}{\\pi_3} & 1 - (\\text{remaining}) \\\\\n",
        "v_1 & v_2 & v_3 & 1 - v_1 - v_2 - v_3\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gaw-jArAJ_uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: when pi4 is small -> required a larger number to get valid result,\n",
        "# so reparameterize the solution to make pi3 becomes the denominator\n",
        "\n",
        "import numpy.linalg as LA\n",
        "import numpy as np\n",
        "\n",
        "pi = np.array([456, 789, 1011, 150])\n",
        "pi = pi / sum(pi)\n",
        "pi1, pi2, pi3, pi4 = pi\n",
        "\n",
        "print(f\"pi={pi}, sum={sum(pi)}\")\n",
        "\n",
        "trials = 0\n",
        "while trials < 100000:\n",
        "\n",
        "  s1,s2,s3,s4 = np.random.dirichlet(np.ones(4))\n",
        "\n",
        "  t1,t2,t3,t4 = np.random.dirichlet(np.ones(4))\n",
        "\n",
        "  v1,v2,v3,v4 = np.random.dirichlet(np.ones(4))\n",
        "\n",
        "  p31 = ((1-s1)*pi1 - t1 * pi2 - v1 * pi4) / pi3\n",
        "  p32 = ((1-t2)*pi2 - s2 * pi1 - v2 * pi4) / pi3\n",
        "  p33 = (pi3 - v3 * pi4 - s3 * pi1 - t3 * pi2) / pi3\n",
        "  p34 = 1 - p31 - p32 - p33\n",
        "\n",
        "  if p31 > 0 and p32 > 0 and p33 > 0 and p34 > 0:\n",
        "    print(f\"trials={trials}\")\n",
        "    break;\n",
        "\n",
        "  trials += 1\n",
        "\n",
        "\n",
        "print(f\"s=({[s1,s2,s3,s4]}), sum={s1+s2+s3+s4}\")\n",
        "print(f\"t=({[t1,t2,t3,t4]}), sum={t1+t2+t3+t4}\")\n",
        "print(f\"v=({[v1,v2,v3,v4]}), sum={v1+v2+v3+v4}\")\n",
        "print(f\"p3=({[p31,p32,p33,p34]}), sum={p31+p32+p33+p34}\")\n",
        "\n",
        "P = [[s1,s2,s3,s4], [t1,t2,t3,t4], [p31,p32,p33,p34], [v1,v2,v3,v4]]\n",
        "\n",
        "p = LA.matrix_power(P, 10000)[0]\n",
        "p\n",
        "\n",
        "# run for different s, the solution will almost the same\n",
        "print(\"\")\n",
        "print(P[0])\n",
        "print(P[1])\n",
        "print(P[2])\n",
        "print(P[3])\n",
        "\n",
        "print(\"\")\n",
        "print(f\"pi={pi}, found P's limiting distribution={p} \\n, norm of diff = {LA.norm(pi-p)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZajEM9YJy1C",
        "outputId": "1b6384d8-8ea8-428f-c83c-422198a5c88a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi=[0.18952618 0.32793017 0.4201995  0.06234414], sum=1.0\n",
            "trials=2\n",
            "s=([0.6322220592969525, 0.12582370799498374, 0.11094831453277997, 0.13100591817528381]), sum=1.0\n",
            "t=([0.08299459909584589, 0.8206725485172591, 0.08560879434414205, 0.010724058042752976]), sum=1.0\n",
            "v=([0.20323736796633432, 0.2210022308537731, 0.5233478529602357, 0.05241254821965685]), sum=1.0\n",
            "p3=([0.070957860612282, 0.05040891567369339, 0.8054995567670514, 0.0731336669469731]), sum=0.9999999999999999\n",
            "\n",
            "[0.6322220592969525, 0.12582370799498374, 0.11094831453277997, 0.13100591817528381]\n",
            "[0.08299459909584589, 0.8206725485172591, 0.08560879434414205, 0.010724058042752976]\n",
            "[0.070957860612282, 0.05040891567369339, 0.8054995567670514, 0.0731336669469731]\n",
            "[0.20323736796633432, 0.2210022308537731, 0.5233478529602357, 0.05241254821965685]\n",
            "\n",
            "pi=[0.18952618 0.32793017 0.4201995  0.06234414], found P's limiting distribution=[0.18952618 0.32793017 0.4201995  0.06234414] \n",
            ", norm of diff = 9.546103868338429e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then the performance will be improved significantly"
      ],
      "metadata": {
        "id": "gwguLkTSR_bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.4: K-states\n",
        "\n",
        "We keep extend the case. Suppose that the required limiting distribution $\\pi = (\\pi_1, \\pi_2, ..., \\pi_K)$ with $\\sum \\pi_i = 1$.\n",
        "\n",
        "With we know that $\\pi_r$ is the largest among all entries of $\\pi$\n",
        "\n",
        "Then,\n",
        "\n",
        "\n",
        "For rows are not at $r$:\n",
        "Simulate using Dirichlet Distribution with length = $K$;\n",
        "\n",
        "For row is at $r$:\n",
        "Using the relationship:\n",
        "$$\n",
        "\\pi_j = \\displaystyle \\sum_{i=1}^K \\pi_i p_{i,j}\n",
        "$$\n",
        "Then, for all $j = 1,2,...,K-1$\n",
        "\n",
        "$$\n",
        "p_{r,j} = \\frac{\\pi_j - \\displaystyle \\sum_{i \\ne r}^K \\pi_i p_{i,j}}{\\pi_r}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "y2LM4Ox3UM0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# revisit Section 2 example 2:\n",
        "import numpy.linalg as LA\n",
        "import numpy as np\n",
        "\n",
        "pi = np.array([0.27269918, 0.16781488, 0.24320997, 0.20882443, 0.1038241, 0.00362744])\n",
        "pi = pi/sum(pi)\n",
        "ind_largest = np.where(pi == max(pi))[0][0]\n",
        "\n",
        "pi_r = pi[ind_largest]\n",
        "print(f\"pi={pi}, sum={sum(pi)}, \\n largest index at: {ind_largest}, its value={pi_r}\")\n",
        "\n",
        "# for handy calculation (calculate the sum except r)\n",
        "pi_star = np.delete(pi, ind_largest)\n",
        "\n",
        "K = len(pi)\n",
        "\n",
        "trials = 0\n",
        "while trials < 10000000:\n",
        "\n",
        "  # generate rows other than r\n",
        "  x = np.random.dirichlet(np.ones(K), size=(K-1))\n",
        "\n",
        "  # own specific row r\n",
        "  p_r = []\n",
        "  for j in range(K-1):\n",
        "\n",
        "    # calculate the specific entry\n",
        "    y_rj = (pi[j] - np.dot(pi_star, x[:, j])) / pi_r\n",
        "\n",
        "    p_r.append(y_rj)\n",
        "  p_r.append(1 - sum(p_r))\n",
        "\n",
        "\n",
        "  # check if all entries of this row (at index of largest pi) are all greater than 0\n",
        "  if all(y_rj>0 for y_rj in p_r):\n",
        "    print(f\"trials={trials}\")\n",
        "    P = np.insert(x, ind_largest, p_r, 0)\n",
        "    break;\n",
        "  else:\n",
        "    if trials%100000 ==0:\n",
        "      print(f\"====> keep running trials={trials}\")\n",
        "  trials += 1\n",
        "\n",
        "print(P)\n",
        "p = LA.matrix_power(P, 10000)[0]\n",
        "p\n",
        "\n",
        "print(\"\")\n",
        "print(f\"pi={pi}, \\n found P's limiting distribution={p} \\n, norm of diff = {LA.norm(pi-p)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KzRrAlCV75Z",
        "outputId": "6fb0e79a-1ca5-4722-f54c-95ab4f31221b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pi=[0.27269918 0.16781488 0.24320997 0.20882443 0.1038241  0.00362744], sum=1.0, \n",
            " largest index at: 0, its value=0.27269918\n",
            "====> keep running trials=0\n",
            "====> keep running trials=100000\n",
            "====> keep running trials=200000\n",
            "====> keep running trials=300000\n",
            "====> keep running trials=400000\n",
            "====> keep running trials=500000\n",
            "====> keep running trials=600000\n",
            "====> keep running trials=700000\n",
            "====> keep running trials=800000\n",
            "====> keep running trials=900000\n",
            "====> keep running trials=1000000\n",
            "====> keep running trials=1100000\n",
            "====> keep running trials=1200000\n",
            "====> keep running trials=1300000\n",
            "====> keep running trials=1400000\n",
            "====> keep running trials=1500000\n",
            "====> keep running trials=1600000\n",
            "====> keep running trials=1700000\n",
            "====> keep running trials=1800000\n",
            "====> keep running trials=1900000\n",
            "====> keep running trials=2000000\n",
            "====> keep running trials=2100000\n",
            "====> keep running trials=2200000\n",
            "====> keep running trials=2300000\n",
            "====> keep running trials=2400000\n",
            "====> keep running trials=2500000\n",
            "trials=2594102\n",
            "[[0.29567213 0.08435917 0.09834794 0.31342973 0.2011734  0.00701762]\n",
            " [0.27591765 0.31401621 0.15915661 0.22209491 0.02629026 0.00252436]\n",
            " [0.33412831 0.19580845 0.3932378  0.00975698 0.06455188 0.00251658]\n",
            " [0.1852827  0.11858426 0.25536834 0.39229495 0.04688905 0.0015807 ]\n",
            " [0.24622814 0.18315612 0.37599785 0.01433711 0.17878119 0.00149958]\n",
            " [0.0681582  0.19620742 0.46246908 0.08250109 0.13765786 0.05300635]]\n",
            "\n",
            "pi=[0.27269918 0.16781488 0.24320997 0.20882443 0.1038241  0.00362744], \n",
            " found P's limiting distribution=[0.27269918 0.16781488 0.24320997 0.20882443 0.1038241  0.00362744] \n",
            ", norm of diff = 1.2454059545748429e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that for the 6 states system, this approach is applicable, but the performance is pretty poor (in terms of number of trials).\n",
        "\n",
        "Also, another obvious drawback of this approach is we cannot easily put extra constraints including specific value of entry; or inequality constraints."
      ],
      "metadata": {
        "id": "eDbHWmFkd54g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B:"
      ],
      "metadata": {
        "id": "QlbjiYtgB9UD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C: Further Readings"
      ],
      "metadata": {
        "id": "H5ELgoKk6Gha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Numpy Eigenvalues / Eigenvectors](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html)\n",
        "\n",
        "\n",
        "[Scipy Optimization](https://docs.scipy.org/doc/scipy/tutorial/optimize.html)\n",
        "\n",
        "[Discrete Time Stochastic Processes](https://www.probabilitycourse.com/chapter11/11_2_1_introduction.php)"
      ],
      "metadata": {
        "id": "o0c8py7hCU46"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWOOtgAnCh8Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}